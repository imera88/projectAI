{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","mount_file_id":"13IEvN5DhIzqv58DUfGGaC3CdW0FHRt5s","authorship_tag":"ABX9TyO0FFCBKJ7Bh/JpLUhIWMjg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"364d3a1c8537468491d806514d761b5c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad9ca7a7653847c4a8f80d1b4a2fcc9c","IPY_MODEL_fc0b6951eca74375811ec461fd3d52bd","IPY_MODEL_120ad295841d4bd78fb15dd2254e74ed"],"layout":"IPY_MODEL_2843f6988246457ab255c34973d7653e"}},"ad9ca7a7653847c4a8f80d1b4a2fcc9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc69e2a5e3e641e5af92dfae13bb9778","placeholder":"​","style":"IPY_MODEL_372b92c529fc441fa75e84d9239ea968","value":"Map: 100%"}},"fc0b6951eca74375811ec461fd3d52bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a90bb14db2f6443fb2938f995d7f6c23","max":2970,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eadf415c171b4563a771256b4c22f36b","value":2970}},"120ad295841d4bd78fb15dd2254e74ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4332a2b3f9c14df38c0cf1c5118787bf","placeholder":"​","style":"IPY_MODEL_6ed3d08c02c84793abef80d43052c569","value":" 2970/2970 [40:01&lt;00:00,  1.35 examples/s]"}},"2843f6988246457ab255c34973d7653e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc69e2a5e3e641e5af92dfae13bb9778":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"372b92c529fc441fa75e84d9239ea968":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a90bb14db2f6443fb2938f995d7f6c23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eadf415c171b4563a771256b4c22f36b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4332a2b3f9c14df38c0cf1c5118787bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ed3d08c02c84793abef80d43052c569":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c015693dc1748a7897f01bc8809bda6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb8a79ec7dcf4ee0857e8ab905432b6f","IPY_MODEL_12ce3a69fa3b4087b56c2ae7ce321c16","IPY_MODEL_d29c0d7c55ea4e74a35b91ae1c9288ca"],"layout":"IPY_MODEL_00bbab04fdd44b4bbb1422f44faa0915"}},"eb8a79ec7dcf4ee0857e8ab905432b6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac4e21db75c44c348a4d12881f0ccbc6","placeholder":"​","style":"IPY_MODEL_b315b06d01d541939ac785f1a0523a18","value":"Map: 100%"}},"12ce3a69fa3b4087b56c2ae7ce321c16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_60f396d1d6d5457d8888b6b821b346c9","max":990,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8240ca59ca814c41a087835bcc335e1c","value":990}},"d29c0d7c55ea4e74a35b91ae1c9288ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a87648f4f39490abb377dc99affcc99","placeholder":"​","style":"IPY_MODEL_72a7b866d0e94638a8ecfdce3cf1ffdc","value":" 990/990 [12:48&lt;00:00,  1.24 examples/s]"}},"00bbab04fdd44b4bbb1422f44faa0915":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac4e21db75c44c348a4d12881f0ccbc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b315b06d01d541939ac785f1a0523a18":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60f396d1d6d5457d8888b6b821b346c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8240ca59ca814c41a087835bcc335e1c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a87648f4f39490abb377dc99affcc99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72a7b866d0e94638a8ecfdce3cf1ffdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d56029d2e3e84f13b415eb68aa46eec8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b81e0e731f141508c57eb9dbea7e09c","IPY_MODEL_1bde1664aa6c4d6289d59af1adee2810","IPY_MODEL_7efbc36aeafd43ffa956cfc315e3eb4c"],"layout":"IPY_MODEL_7d028d1f9a1345b4b4e86396ee907ec0"}},"6b81e0e731f141508c57eb9dbea7e09c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cb0cab7e50b4bc3a674367219cf02d0","placeholder":"​","style":"IPY_MODEL_87dd219bd1704ba4b64a76f0b4cf5080","value":"Downloading builder script: 100%"}},"1bde1664aa6c4d6289d59af1adee2810":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_412f438252bd4a46a48f513276a69485","max":4485,"min":0,"orientation":"horizontal","style":"IPY_MODEL_936e1af794354d57bd3b2632b543562e","value":4485}},"7efbc36aeafd43ffa956cfc315e3eb4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_947484b0502e45afab55642752d78e0c","placeholder":"​","style":"IPY_MODEL_b3945561562c4d6b885d2a0097c10d56","value":" 4.49k/4.49k [00:00&lt;00:00, 348kB/s]"}},"7d028d1f9a1345b4b4e86396ee907ec0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cb0cab7e50b4bc3a674367219cf02d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87dd219bd1704ba4b64a76f0b4cf5080":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"412f438252bd4a46a48f513276a69485":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"936e1af794354d57bd3b2632b543562e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"947484b0502e45afab55642752d78e0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3945561562c4d6b885d2a0097c10d56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n","!pip install transformers datasets torchaudio jiwer\n","!pip install evaluate librosa\n","!pip install evaluate\n","!pip install -U bitsandbytes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jKRh9BoxS1gs","executionInfo":{"status":"ok","timestamp":1734068545311,"user_tz":300,"elapsed":16703,"user":{"displayName":"Marcos Irving Mera Sanchez","userId":"00640408618716900836"}},"outputId":"5cd7f837-ad79-456e-c982-8ec118acfe21"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n","Collecting datasets\n","  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Collecting jiwer\n","  Downloading jiwer-3.0.5-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n","Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.5.1+cu121)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n","Collecting rapidfuzz<4,>=3 (from jiwer)\n","  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchaudio) (3.0.2)\n","Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiwer-3.0.5-py3-none-any.whl (21 kB)\n","Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, rapidfuzz, fsspec, dill, multiprocess, jiwer, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 jiwer-3.0.5 multiprocess-0.70.16 rapidfuzz-3.10.1 xxhash-3.5.0\n","Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.3\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.9.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n","Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.45.0\n"]}]},{"cell_type":"code","source":["pip install --upgrade transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSYbkGb4hLMJ","executionInfo":{"status":"ok","timestamp":1734068556751,"user_tz":300,"elapsed":11446,"user":{"displayName":"Marcos Irving Mera Sanchez","userId":"00640408618716900836"}},"outputId":"cdcfb2c7-13b6-447a-bb86-8dc7f679e6d2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n","Collecting transformers\n","  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Collecting tokenizers<0.22,>=0.21 (from transformers)\n","  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.20.3\n","    Uninstalling tokenizers-0.20.3:\n","      Successfully uninstalled tokenizers-0.20.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.46.3\n","    Uninstalling transformers-4.46.3:\n","      Successfully uninstalled transformers-4.46.3\n","Successfully installed tokenizers-0.21.0 transformers-4.47.0\n"]}]},{"cell_type":"code","source":["from transformers import WhisperForConditionalGeneration, WhisperProcessor, Seq2SeqTrainer, Seq2SeqTrainingArguments\n","import torch\n","import evaluate\n","from datasets import load_dataset, DatasetDict, Audio\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","import os\n","import torch\n","import os\n","import pandas as pd\n","from datasets import Dataset\n","from transformers import DataCollatorForSeq2Seq\n","\n","# Configuración de rutas y modelo\n","output_dir = \"/content/drive/MyDrive/Proyecto_ASR_AG/Whisper_Model/\"\n","\n","\n","# Ruta base de la carpeta que contiene los archivos CSV y audios\n","base_path = \"/content/drive/MyDrive/Proyecto_ASR_AG/Aligned_VF_Fix/\"\n","\n","# Obtener todas las rutas de los archivos CSV en el directorio base\n","def get_csv_paths(base_path):\n","    csv_paths = []\n","    for root, _, files in os.walk(base_path):\n","        for file in files:\n","            if file.endswith(\".csv\"):  # Filtrar archivos CSV\n","                csv_paths.append(os.path.join(root, file))\n","    if not csv_paths:\n","        print(\"No se encontraron archivos CSV en la ruta especificada.\")\n","    else:\n","        print(f\"Se encontraron {len(csv_paths)} archivos CSV.\")\n","    return csv_paths\n","\n","# Crear dataset a partir de múltiples archivos CSV\n","def create_dataset_from_multiple_csvs(base_path):\n","    data = {'audio': [], 'text': []}\n","\n","    # Obtener todas las rutas de los archivos CSV\n","    csv_paths = get_csv_paths(base_path)\n","\n","    # Procesar cada archivo CSV\n","    for csv_path in csv_paths:\n","        df = pd.read_csv(csv_path)\n","        df = df[['audio_file', 'sentence']].drop_duplicates()\n","        #print(df)\n","\n","        # Iterar sobre cada fila y agregar la ruta completa del audio y su transcripción\n","        for _, row in df.iterrows():\n","            audio_file = row['audio_file']  # Columna con la ruta del archivo de audio\n","            transcription = row['sentence']  # Columna con la transcripción\n","            if os.path.exists(audio_file):\n","                data['audio'].append(audio_file)\n","                data['text'].append(transcription)\n","            else:\n","                print(f\"Archivo de audio no encontrado: {audio_file}\")\n","\n","    # Convertir a Dataset de Hugging Face\n","    dataset = Dataset.from_dict(data).cast_column(\"audio\", Audio(sampling_rate=16_000))\n","    return dataset\n","\n","# Crear el dataset\n","dataset = create_dataset_from_multiple_csvs(base_path)"],"metadata":{"id":"L0MsSFbWf4YP","executionInfo":{"status":"ok","timestamp":1734068630215,"user_tz":300,"elapsed":73469,"user":{"displayName":"Marcos Irving Mera Sanchez","userId":"00640408618716900836"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"43f5fcfd-d4ca-46aa-ebc3-85b98a053343"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Se encontraron 327 archivos CSV.\n"]}]},{"cell_type":"code","source":["!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"],"metadata":{"id":"LN-v8A5m8l7a","executionInfo":{"status":"ok","timestamp":1734068630216,"user_tz":300,"elapsed":15,"user":{"displayName":"Marcos Irving Mera Sanchez","userId":"00640408618716900836"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# División del dataset en entrenamiento y prueba\n","dataset = dataset.train_test_split(test_size=0.25)"],"metadata":{"id":"clysAFFrwVhr","executionInfo":{"status":"ok","timestamp":1734068630216,"user_tz":300,"elapsed":11,"user":{"displayName":"Marcos Irving Mera Sanchez","userId":"00640408618716900836"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(dataset)#"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgT5CAaQmzcc","executionInfo":{"status":"ok","timestamp":1734068630216,"user_tz":300,"elapsed":10,"user":{"displayName":"Marcos Irving Mera Sanchez","userId":"00640408618716900836"}},"outputId":"2b317974-481f-470b-83b9-abd9453ac89f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['audio', 'text'],\n","        num_rows: 2970\n","    })\n","    test: Dataset({\n","        features: ['audio', 'text'],\n","        num_rows: 990\n","    })\n","})\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset, DatasetDict, Audio\n","from transformers import (\n","    WhisperForConditionalGeneration,\n","    WhisperProcessor,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq,\n",")\n","from evaluate import load\n","import torch\n","\n","# Liberar memoria no utilizada\n","torch.cuda.empty_cache()\n","\n","# Cargar procesador y modelo\n","processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n","model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n","\n","# Configuración del idioma (español)\n","processor.feature_extractor.sampling_rate = 16000\n","model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"es\", task=\"transcribe\")\n","\n","# Función de preprocesamiento\n","def preprocess(batch):\n","    audio = batch[\"audio\"]\n","    batch[\"input_features\"] = processor.feature_extractor(\n","        audio[\"array\"],\n","        sampling_rate=audio[\"sampling_rate\"]\n","    ).input_features[0]\n","    labels = processor.tokenizer(\n","        batch[\"text\"],\n","        return_tensors=\"pt\",\n","        padding=\"longest\"\n","    ).input_ids[0]\n","    labels[labels == processor.tokenizer.pad_token_id] = -100\n","    batch[\"labels\"] = labels\n","    return batch\n","\n","# Preprocesar el dataset\n","data = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n","data = dataset.map(preprocess, remove_columns=[\"audio\", \"text\"])\n","\n","# Métrica de evaluación\n","wer_metric = load(\"wer\")\n","\n","def compute_metrics(pred):\n","    pred_ids = pred.predictions\n","    label_ids = pred.label_ids\n","    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n","    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n","    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n","    return {\"wer\": wer}\n","\n","# Data collator personalizado\n","def whisper_data_collator(features):\n","    input_features = torch.stack([torch.tensor(f[\"input_features\"]) for f in features])\n","    labels = torch.nn.utils.rnn.pad_sequence(\n","        [torch.tensor(f[\"labels\"]) for f in features],\n","        batch_first=True,\n","        padding_value=-100,\n","    )\n","    return {\"input_features\": input_features, \"labels\": labels}\n","\n","# Configuración de argumentos de entrenamiento\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./whisper-small-finetuned\",\n","    eval_strategy=\"epoch\",\n","    learning_rate=1e-5,\n","    per_device_train_batch_size=4,  # Reducir tamaño del lote\n","    per_device_eval_batch_size=4,  # Reducir tamaño del lote\n","    gradient_accumulation_steps=2,  # Acumulación de gradientes\n","    num_train_epochs=5,\n","    predict_with_generate=True,\n","    save_strategy=\"epoch\",\n","    fp16=torch.cuda.is_available(),\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to=\"none\"\n",")\n","\n","# Inicializar el entrenador\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=data[\"train\"],\n","    eval_dataset=data[\"test\"],\n","    data_collator=whisper_data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Liberar memoria no utilizada\n","torch.cuda.empty_cache()\n","\n","# Entrenamiento\n","trainer.train()\n","\n","# Guardar el modelo y el procesador\n","trainer.save_model(\"./whisper-small-finetuned\")\n","processor.save_pretrained(\"./whisper-small-finetuned\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["364d3a1c8537468491d806514d761b5c","ad9ca7a7653847c4a8f80d1b4a2fcc9c","fc0b6951eca74375811ec461fd3d52bd","120ad295841d4bd78fb15dd2254e74ed","2843f6988246457ab255c34973d7653e","bc69e2a5e3e641e5af92dfae13bb9778","372b92c529fc441fa75e84d9239ea968","a90bb14db2f6443fb2938f995d7f6c23","eadf415c171b4563a771256b4c22f36b","4332a2b3f9c14df38c0cf1c5118787bf","6ed3d08c02c84793abef80d43052c569","4c015693dc1748a7897f01bc8809bda6","eb8a79ec7dcf4ee0857e8ab905432b6f","12ce3a69fa3b4087b56c2ae7ce321c16","d29c0d7c55ea4e74a35b91ae1c9288ca","00bbab04fdd44b4bbb1422f44faa0915","ac4e21db75c44c348a4d12881f0ccbc6","b315b06d01d541939ac785f1a0523a18","60f396d1d6d5457d8888b6b821b346c9","8240ca59ca814c41a087835bcc335e1c","2a87648f4f39490abb377dc99affcc99","72a7b866d0e94638a8ecfdce3cf1ffdc","d56029d2e3e84f13b415eb68aa46eec8","6b81e0e731f141508c57eb9dbea7e09c","1bde1664aa6c4d6289d59af1adee2810","7efbc36aeafd43ffa956cfc315e3eb4c","7d028d1f9a1345b4b4e86396ee907ec0","9cb0cab7e50b4bc3a674367219cf02d0","87dd219bd1704ba4b64a76f0b4cf5080","412f438252bd4a46a48f513276a69485","936e1af794354d57bd3b2632b543562e","947484b0502e45afab55642752d78e0c","b3945561562c4d6b885d2a0097c10d56"]},"id":"Xnqkd4GavSIo","executionInfo":{"status":"ok","timestamp":1734085969042,"user_tz":300,"elapsed":17252883,"user":{"displayName":"Marcos Irving Mera Sanchez","userId":"00640408618716900836"}},"outputId":"8b7e1449-9149-4091-bcc9-915b4e80a2e1"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2970 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"364d3a1c8537468491d806514d761b5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/990 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c015693dc1748a7897f01bc8809bda6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d56029d2e3e84f13b415eb68aa46eec8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1855' max='1855' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1855/1855 3:54:28, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Wer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.375500</td>\n","      <td>0.395817</td>\n","      <td>8.114471</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.346900</td>\n","      <td>0.283871</td>\n","      <td>7.554474</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.047000</td>\n","      <td>0.240880</td>\n","      <td>6.225683</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.017200</td>\n","      <td>0.220716</td>\n","      <td>5.704029</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n","The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n","import bitsandbytes as bnb\n","print(bnb.__version__)\n","\n","!pip install transformers==4.33.3\n","!pip install peft==0.4.0\n","!pip install bitsandbytes==0.41.1\n","!pip install accelerate==0.21.0"],"metadata":{"id":"RlWny75k3dEA","executionInfo":{"status":"aborted","timestamp":1734068707128,"user_tz":300,"elapsed":5,"user":{"displayName":"Marcos Irving Mera Sanchez","userId":"00640408618716900836"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","from datasets import load_dataset, DatasetDict\n","from transformers import (\n","    AutoProcessor, AutoModelForSpeechSeq2Seq,\n","    WhisperForConditionalGeneration,\n","    WhisperProcessor,\n","    WhisperTokenizer,\n","    Seq2SeqTrainer,\n","    Seq2SeqTrainingArguments,\n","    BitsAndBytesConfig\n",")\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from peft import LoraConfig, get_peft_model, TaskType\n","\n","# Configuración básica\n","MODEL_NAME = \"openai/whisper-small\"  # Modelo base de Whisper\n","LANGUAGE = \"es\"  # Idioma Español\n","OUTPUT_DIR = \"./whisper-finetuned-es\"  # Directorio de salida\n","\n","processor = AutoProcessor.from_pretrained(\"openai/whisper-medium\")\n","model = AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-medium\")\n","\n","for name, module in model.named_modules():\n","    print(name)\n","\n","lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    lora_dropout=0.1,\n","    task_type=TaskType.SEQ_2_SEQ_LM,\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]  # Asegúrate de usar nombres válidos\n",")\n","\n","model = get_peft_model(model, lora_config)\n","\n","for param in model.base_model.parameters():\n","    param.requires_grad = False\n","\n","for name, param in model.named_parameters():\n","    if \"lora\" in name:\n","        param.requires_grad = True\n","\n","\n","class DataCollatorWithPadding:\n","    def __init__(self, processor):\n","        self.tokenizer = processor.tokenizer\n","\n","    def __call__(self, features):\n","        input_features = torch.stack([torch.tensor(f[\"input_features\"]) for f in features])\n","        labels = torch.nn.utils.rnn.pad_sequence(\n","            [torch.tensor(f[\"labels\"]) for f in features],\n","            batch_first=True,\n","            padding_value=self.tokenizer.pad_token_id,\n","        )\n","        return {\"input_features\": input_features, \"labels\": labels}\n","\n","data_collator = DataCollatorWithPadding(processor)\n","\n","#data_collator = DataCollatorWithPaddingForWhisper(processor)\n","\n","# Métricas adicionales\n","wer_metric = evaluate.load(\"wer\")\n","cer_metric = evaluate.load(\"cer\")\n","\n","#def compute_metrics(pred):\n","#    # Convertir predicciones a logits y luego a índices\n","#    pred_logits = torch.from_numpy(pred.predictions)  # Convertir a tensor\n","#    pred_ids = [torch.argmax(batch, dim=-1).tolist() for batch in pred_logits]\n","\n","#\n","    # Validar y convertir pred_ids a lista de listas\n","#    if isinstance(pred_ids, torch.Tensor):\n","#        pred_ids = pred_ids.tolist()\n","#    if isinstance(pred_ids[0], int):  # Si es una lista plana, convertirla en lista de listas\n","#        pred_ids = [pred_ids]\n","\n","    # Decodificar predicciones y etiquetas\n","#    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n","#    label_ids = pred.label_ids\n","#    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n","#    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n","\n","    # Filtrar secuencias vacías de forma consistente\n","#    filtered_pairs = [(p, l) for p, l in zip(pred_str, label_str) if l.strip()]\n","#    filtered_pred_str, filtered_label_str = zip(*filtered_pairs) if filtered_pairs else ([], [])\n","\n","    # Validar tamaños\n","#    if len(filtered_pred_str) != len(filtered_label_str):\n","#        print(f\"Filtered Predictions: {filtered_pred_str}\")\n","#        print(f\"Filtered References: {filtered_label_str}\")\n","#        raise ValueError(\n","#            f\"Mismatch in filtered predictions ({len(filtered_pred_str)}) \"\n","#            f\"and references ({len(filtered_label_str)})\"\n","#        )\n","\n","    # Calcular métricas\n","#   wer_score = wer_metric.compute(predictions=list(filtered_pred_str), references=list(filtered_label_str))\n","#   cer_score = cer_metric.compute(predictions=list(filtered_pred_str), references=list(filtered_label_str))\n","\n","#    return {\"wer\": wer_score, \"cer\": cer_score}\n","\n","def compute_metrics(pred):\n","    pred_ids = pred.predictions\n","    label_ids = pred.label_ids\n","    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n","    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n","    wer_score = wer_metric.compute(predictions=pred_str, references=label_str)\n","    cer_score = cer_metric.compute(predictions=pred_str, references=label_str)\n","    return {\"wer\": wer_score, \"cer\": cer_score}\n","\n","# Generar predicciones en conjunto de prueba\n","def transcribe(batch):\n","    inputs = processor.feature_extractor(batch[\"audio\"][\"array\"], sampling_rate=batch[\"audio\"][\"sampling_rate\"], return_tensors=\"pt\").input_features\n","    inputs = inputs.to(model.device)\n","    predicted_ids = model.generate(inputs)\n","    batch[\"predicted_text\"] = processor.tokenizer.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n","    return batch\n","\n","def prepare_dataset(batch):\n","    audio = batch[\"audio\"][\"array\"]\n","    input_features = processor(audio, sampling_rate=16_000).input_features[0]\n","    labels = processor(\n","        text=batch[\"text\"], return_tensors=\"pt\", padding=True, truncation=True\n","    ).input_ids[0]\n","\n","    # Convertir padding a -100\n","    labels[labels == processor.tokenizer.pad_token_id] = -100\n","    batch[\"input_features\"] = input_features\n","    batch[\"labels\"] = labels.tolist()  # Convertir a lista\n","    return batch\n","\n","def predict_batch(batch):\n","    inputs = processor(batch[\"audio\"][\"array\"],\n","                       sampling_rate=batch[\"audio\"][\"sampling_rate\"],\n","                       return_tensors=\"pt\",\n","                       padding=True,\n","                       truncation=True).input_features\n","    inputs = inputs.to(model.device)\n","    predicted_ids = model.generate(inputs)\n","    batch[\"predicted_text\"] = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n","    return batch\n","\n","# Agregar feature de sampling rate\n","def preprocess_audio(batch):\n","    audio = batch[\"audio\"][\"array\"]\n","    input_features = processor.feature_extractor(audio, sampling_rate=16000).input_features[0]\n","    labels = processor.tokenizer(\n","        batch[\"text\"], truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\"\n","    ).input_ids[0]\n","    labels[labels == processor.tokenizer.pad_token_id] = -100  # Ignorar padding en la pérdida\n","    batch[\"input_features\"] = input_features\n","    batch[\"labels\"] = labels\n","    return batch\n","\n","dataset = dataset.map(preprocess_audio, remove_columns=[\"audio\", \"text\"], num_proc=4)\n","\n","# Dividir el dataset en entrenamiento y validación\n","train_dataset = dataset[\"train\"]\n","test_dataset = dataset[\"test\"]\n","\n","# Cargar modelo de Whisper\n","#model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME,  load_in_8bit=True, device_map=\"auto\")\n","\n","for param in model.model.encoder.parameters():\n","    param.requires_grad = False\n","\n","# Configurar entrenamiento\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    eval_strategy=\"epoch\",\n","    learning_rate=1e-4,\n","    per_device_train_batch_size=2,  # Reducir tamaño del batch\n","    per_device_eval_batch_size=2,  # Reducir tamaño del batch\n","    gradient_accumulation_steps=4,  # Acumular gradientes\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=8,\n","    predict_with_generate=True,\n","    fp16=torch.cuda.is_available(),\n","    save_strategy=\"epoch\",\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    generation_max_length=128,  # Reducir la longitud máxima de generación\n","    report_to=\"none\",\n","    gradient_checkpointing=True,\n",")\n","\n","#trainer = Seq2SeqTrainer(\n","#    model=model,\n","#    args=training_args,\n","#    train_dataset=dataset[\"train\"],\n","#    eval_dataset=dataset[\"test\"],\n","#    processing_class=processor,  # Usa processing_class en lugar de tokenizer\n","#    data_collator=data_collator,\n","#    compute_metrics=compute_metrics,\n","#)\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    tokenizer=processor.tokenizer,\n","    #processing_class=processor,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Entrenamiento\n","trainer.train()\n","\n","# Evaluación\n","results = trainer.evaluate()\n","print(\"Resultados de la evaluación:\", results)\n","\n","# Guardar el modelo ajustado\n","model.save_pretrained(OUTPUT_DIR)\n","processor.save_pretrained(OUTPUT_DIR)"],"metadata":{"id":"08RBfct3mVW4","collapsed":true,"executionInfo":{"status":"aborted","timestamp":1734068707128,"user_tz":300,"elapsed":4,"user":{"displayName":"Marcos Irving Mera Sanchez","userId":"00640408618716900836"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Columnas del test_dataset: {test_dataset.column_names}\")"],"metadata":{"id":"M2E_EYRxFZMi","executionInfo":{"status":"aborted","timestamp":1734068707128,"user_tz":300,"elapsed":4,"user":{"displayName":"Marcos Irving Mera Sanchez","userId":"00640408618716900836"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = test_dataset.map(predict_batch, batched=True, batch_size=16, remove_columns=test_dataset.column_names)\n","\n","pred_texts = []\n","for pred in predictions:\n","    pred_texts.extend(pred[\"predicted_text\"])\n","\n","label_texts = predictions[\"text\"]\n","\n","# Calcular métricas\n","metrics = compute_metrics(pred_texts, label_texts)\n","\n","# Mostrar métricas\n","print(\"Métricas de evaluación:\")\n","for metric, value in metrics.items():\n","    print(f\"{metric}: {value:.4f}\")\n","\n","\n","\n","# Generate predictions\n","predictions = trainer.predict(test_dataset)\n","\n","# Extract predicted and label texts\n","pred_texts = processor.batch_decode(predictions.predictions, skip_special_tokens=True)\n","label_texts = processor.batch_decode(predictions.label_ids, skip_special_tokens=True)\n","\n","# Calculate metrics\n","metrics = compute_metrics(EvalPrediction(predictions=pred_texts, label_ids=label_texts)) # Update compute_metrics to accept EvalPrediction\n","\n","# Display metrics\n","print(\"Evaluation Metrics:\")\n","for metric, value in metrics.items():\n","    print(f\"{metric}: {value:.4f}\")"],"metadata":{"id":"M0l2frF-QbHp","executionInfo":{"status":"aborted","timestamp":1734068707129,"user_tz":300,"elapsed":5,"user":{"displayName":"Marcos Irving Mera Sanchez","userId":"00640408618716900836"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Código de prueba"],"metadata":{"id":"8BR0vARXmYOX"}},{"cell_type":"code","source":["#import torch\n","#import numpy as np\n","#torch.cuda.empty_cache()  # Liberar memoria GPU antes de entrenar\n","\n","\n","#from transformers import WhisperProcessor\n","\n","#processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n","#trainer = Trainer(\n","#    model=model,\n","#    args=training_args,\n","#    train_dataset=train_dataset,\n","#    eval_dataset=eval_dataset,\n","#    tokenizer=processor,  # Se puede reemplazar con `processing_class` si aplica\n","#)\n","\n","\n","# Cargar métricas de evaluación\n","#wer_metric = evaluate.load(\"wer\")\n","#cer_metric = evaluate.load(\"cer\")\n","\n","# Cargar el modelo y procesador\n","#model_name = \"openai/whisper-small\"  # Usar un modelo más pequeño para reducir memoria\n","#processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n","#model = WhisperForConditionalGeneration.from_pretrained(model_name)\n","\n","# Configuración del modelo\n","#model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"es\", task=\"transcribe\")\n","#model.config.suppress_tokens = []\n","#model.config.use_cache = False  # Desactivar cache para gradient checkpointing\n","#processor.tokenizer.pad_token_id = processor.tokenizer.eos_token_id\n","\n","# Activar gradient checkpointing\n","#model.gradient_checkpointing_enable()\n","\n","# Preprocesamiento de datos\n","#def prepare_dataset(batch):\n","#    audio = batch[\"audio\"][\"array\"]\n","#    batch[\"input_features\"] = processor(audio, sampling_rate=16_000).input_features[0]\n","#    batch[\"labels\"] = processor(text=batch[\"text\"], return_tensors=\"pt\", padding=True, truncation=True).input_ids[0]\n","#    return batch\n","\n","#def prepare_dataset(batch):\n","#    audio = batch[\"audio\"][\"array\"]\n","#    batch[\"input_features\"] = processor(audio, sampling_rate=16_000).input_features[0]\n","#    labels = processor(text=batch[\"text\"], return_tensors=\"pt\", padding=True, truncation=True).input_ids[0]\n","#    labels[labels == processor.tokenizer.pad_token_id] = -100  # Etiquetas ignoradas\n","#    batch[\"labels\"] = labels\n","#    return batch\n","\n","#def preprocess_function(batch):\n","#    # Tokenización y procesamiento\n","#    inputs = processor(\n","#        batch[\"audio\"][\"array\"], sampling_rate=batch[\"audio\"][\"sampling_rate\"], return_tensors=\"pt\"\n","#    )\n","#    batch[\"input_features\"] = inputs.input_features[0]\n","#    batch[\"labels\"] = processor.tokenizer(batch[\"sentence\"], return_tensors=\"pt\").input_ids[0]\n","#    return batch\n","\n","# Filtrar datos vacíos\n","#def filter_empty_texts(batch):\n","#    return batch[\"text\"].strip() != \"\"\n","\n","# Preprocesar y filtrar el dataset\n","#dataset = dataset.filter(filter_empty_texts)\n","#dataset = dataset.map(prepare_dataset, remove_columns=[\"audio\", \"text\"])\n","\n","#class DataCollatorWithPaddingForWhisper:\n","#    def __init__(self, tokenizer):\n","#        # Manejar tanto el procesador como el tokenizador directamente\n","#        self.tokenizer = tokenizer.tokenizer if hasattr(tokenizer, \"tokenizer\") else tokenizer\n","\n","#    def __call__(self, features):\n","#        input_features = torch.stack([torch.tensor(f[\"input_features\"]) for f in features])\n","#        labels = torch.nn.utils.rnn.pad_sequence(\n","#            [torch.tensor(f[\"labels\"]) for f in features],\n","#            batch_first=True,\n","#            padding_value=self.tokenizer.pad_token_id,\n","#        )\n","#       return {\"input_features\": input_features, \"labels\": labels}\n","\n","#data_collator = DataCollatorWithPaddingForWhisper(processor)\n","\n","\n","# Función para calcular métricas\n","#def compute_metrics(pred):\n","#    if not isinstance(pred.predictions, np.ndarray):\n","#        raise TypeError(\"`pred.predictions` no es un array numpy.\")\n","#    pred_logits = torch.from_numpy(pred.predictions)\n","#    pred_ids = torch.argmax(pred_logits, dim=-1).tolist()  # Convertir a lista de listas\n","#    if not isinstance(pred_ids, list) or not all(isinstance(seq, list) for seq in pred_ids):\n","#        raise ValueError(\"El formato de `pred_ids` es incorrecto. Se espera una lista de listas.\")\n","#\n","#    # Decodificar predicciones y etiquetas\n","#    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n","#    label_str = processor.batch_decode(pred.label_ids.tolist(), skip_special_tokens=True)\n","#\n","#    pred_logits = torch.from_numpy(pred.predictions)\n","#    pred_ids = torch.argmax(pred_logits, dim=-1).tolist()  # Convertir a lista\n","#\n","#    # Decodificar predicciones y etiquetas\n","#    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n","#    label_str = processor.batch_decode(pred.label_ids.tolist(), skip_special_tokens=True)\n","#\n","#    # Filtrar predicciones y etiquetas vacías\n","#    filtered_pred_str = []\n","#    filtered_label_str = []\n","#    for pred, label in zip(pred_str, label_str):\n","#        if label.strip():  # Excluir etiquetas vacías\n","#            filtered_pred_str.append(pred)\n","#            filtered_label_str.append(label)\n","\n","#    # Si no hay etiquetas válidas, retornar métricas por defecto\n","#    if not filtered_label_str:\n","#        return {\n","#            \"wer\": 1.0,\n","#            \"cer\": 1.0,\n","#            \"precision\": 0.0,\n","#            \"accuracy\": 0.0,\n","#            \"f1\": 0.0,\n","#        }\n","#\n","#    # Calcular WER y CER\n","#    wer_score = wer_metric.compute(predictions=filtered_pred_str, references=filtered_label_str)\n","#    cer_score = cer_metric.compute(predictions=filtered_pred_str, references=filtered_label_str)\n","#\n","#    # Calcular métricas de clasificación\n","#    pred_chars = [char for pred in filtered_pred_str for char in pred]\n","#    label_chars = [char for label in filtered_label_str for char in label]\n","#    min_len = min(len(pred_chars), len(label_chars))\n","#    pred_chars = pred_chars[:min_len]\n","#    label_chars = label_chars[:min_len]\n","#\n","#    precision = precision_score(label_chars, pred_chars, average=\"macro\", zero_division=0)\n","#    accuracy = accuracy_score(label_chars, pred_chars)\n","#    f1 = f1_score(label_chars, pred_chars, average=\"macro\", zero_division=0)\n","#\n","#    return {\n","#        \"wer\": wer_score,\n","#        \"cer\": cer_score,\n","#        \"precision\": precision,\n","#        \"accuracy\": accuracy,\n","#        \"f1\": f1,\n","#    }\n","\n","\n","#def compute_metrics(pred):\n","\n","#    print(f\"Predictions shape: {pred.predictions.shape}\")\n","#    print(f\"Label IDs shape: {pred.label_ids.shape}\")\n","#    pred_logits = torch.from_numpy(pred.predictions)  # Convertir a tensor\n","#    pred_ids = torch.argmax(pred_logits, dim=-1).tolist()  # Convertir a lista\n","\n","    # Verificar y convertir pred_ids a lista de listas si es necesario\n","#    if not isinstance(pred_ids, list) or not all(isinstance(seq, list) for seq in pred_ids):\n","#        pred_ids = [pred.tolist() for pred in pred_logits.argmax(dim=-1)]\n","\n","    # Decodificar predicciones y etiquetas\n","#    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n","#    label_ids = pred.label_ids\n","#    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id  # Manejar etiquetas -100\n","#    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n","\n","    # Filtrar secuencias vacías\n","#    filtered_pred_str = [pred for pred, label in zip(pred_str, label_str) if label.strip()]\n","#    filtered_label_str = [label for label in label_str if label.strip()]\n","\n","#   if not filtered_label_str:\n","#       return {\"wer\": 1.0, \"cer\": 1.0}\n","\n","    # Calcular WER y CER\n","#    wer_score = wer_metric.compute(predictions=filtered_pred_str, references=filtered_label_str)\n","#    cer_score = cer_metric.compute(predictions=filtered_pred_str, references=filtered_label_str)\n","\n","#    return {\"wer\": wer_score, \"cer\": cer_score}\n","\n","\n","# Argumentos de entrenamiento\n","#training_args = Seq2SeqTrainingArguments(\n","#    output_dir=\"./whisper-small-output\",\n","#    per_device_train_batch_size=2,  # Reducir tamaño del lote\n","#    per_device_eval_batch_size=2,\n","#    gradient_accumulation_steps=8,  # Acumular gradientes\n","#    eval_strategy=\"epoch\",\n","#    save_strategy=\"epoch\",\n","#    learning_rate=2e-5,\n","#    warmup_steps=500,\n","#    save_total_limit=2,\n","#    num_train_epochs=8,\n","#    predict_with_generate=True,\n","#    fp16=True,  # Activar precisión mixta\n","#    push_to_hub=False,\n","#)\n","\n","# Configurar el entrenador\n","#trainer = Seq2SeqTrainer(\n","#    model=model,\n","#    args=training_args,\n","#    train_dataset=dataset[\"train\"],\n","#    eval_dataset=dataset[\"test\"],\n","#    tokenizer=processor,  # Usa processor directamente\n","#    data_collator=data_collator,\n","#    compute_metrics=compute_metrics,\n","#)\n","\n","#data_collator = DataCollatorForSeq2Seq(\n","#    tokenizer=tokenizer,\n","#    model=model,\n","#    padding=True,\n","#    truncation=True\n","#)\n","\n","#trainer = Trainer(\n","#    model=model,\n","#    args=training_args,\n","#    train_dataset=train_dataset,\n","#    eval_dataset=eval_dataset,\n","#    data_collator=data_collator,\n","#)\n","\n","# Entrenar el modelo\n","#trainer.train()\n","\n","# Evaluar el modelo\n","#eval_results = trainer.evaluate()\n","#print(f\"Resultados de la evaluación: {eval_results}\")\n","\n","# Guardar el modelo y el procesador\n","#model.save_pretrained(\"./whisper-small-final\")\n","#processor.save_pretrained(\"./whisper-small-final\")"],"metadata":{"id":"dXCmnpgmFYiT","executionInfo":{"status":"aborted","timestamp":1734068707129,"user_tz":300,"elapsed":5,"user":{"displayName":"Marcos Irving Mera Sanchez","userId":"00640408618716900836"}}},"execution_count":null,"outputs":[]}]}